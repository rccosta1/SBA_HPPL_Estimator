{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNa2pKo5PJPP83mXFnYBRw6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# About this notebook"],"metadata":{"id":"KiVOpZ2Tkqcs"}},{"cell_type":"markdown","source":["\n","\n","---\n","\n","\n","\n","---\n","\n"],"metadata":{"id":"UmpL6B2FkvIl"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FY9sGRnkV7k","executionInfo":{"status":"ok","timestamp":1663353818113,"user_tz":240,"elapsed":18213,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"f4803e64-d6ac-43c2-fe8c-58208b8dfbc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["# Mount YOUR google drive. You'll need to \"Add shortcut to Drive\" for our shared folder for it to show up here.\n","# Use the URL shown below in the output to authorize this Colab session to access you GDrive\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)\n","\n","# Modify this according to the path in your computer\n","data_dir = '/content/drive/MyDrive/SURI/Studies/2022_Wildfires/' # <-- change this to reflect the pathing in your machine"]},{"cell_type":"code","source":["# Import needed packages\n","! pip install geopandas\n","! pip install geopy\n","! pip install -U plotly\n","! pip install cmcrameri\n","! pip install cpi\n","! pip install requests\n","!pip install adjustText\n","\n","import pandas as pd\n","import geopandas as gpd\n","import geopy\n","from geopy.geocoders import Nominatim\n","from geopy.extra.rate_limiter import RateLimiter\n","import geopy.distance\n","from shapely.geometry import Point, Polygon\n","import csv\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy \n","from scipy import stats as sts\n","import plotly.express as px\n","from numpy.random import default_rng\n","from plotnine import *\n","import time\n","from cmcrameri import cm\n","import cpi\n","import requests \n","\n","rng = default_rng(13)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eg2_O7NNkz1O","executionInfo":{"status":"ok","timestamp":1663353889710,"user_tz":240,"elapsed":71602,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"e3b6eb61-55f3-455c-e05e-ead1a66062ac"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting geopandas\n","  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 20.7 MB/s \n","\u001b[?25hCollecting pyproj>=2.2.0\n","  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 63.2 MB/s \n","\u001b[?25hCollecting fiona>=1.8\n","  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n","\u001b[K     |████████████████████████████████| 16.7 MB 60.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n","Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.4)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Collecting click-plugins>=1.0\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.6.15)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.2.1)\n","Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (1.17.0)\n","Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy) (1.52)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Collecting plotly\n","  Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\n","\u001b[K     |████████████████████████████████| 15.2 MB 41.9 MB/s \n","\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n","Installing collected packages: plotly\n","  Attempting uninstall: plotly\n","    Found existing installation: plotly 5.5.0\n","    Uninstalling plotly-5.5.0:\n","      Successfully uninstalled plotly-5.5.0\n","Successfully installed plotly-5.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cmcrameri\n","  Downloading cmcrameri-1.4-py3-none-any.whl (134 kB)\n","\u001b[K     |████████████████████████████████| 134 kB 41.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cmcrameri) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cmcrameri) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cmcrameri) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cmcrameri) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cmcrameri) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cmcrameri) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->cmcrameri) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->cmcrameri) (1.15.0)\n","Installing collected packages: cmcrameri\n","Successfully installed cmcrameri-1.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cpi\n","  Downloading cpi-1.0.11-py2.py3-none-any.whl (29.6 MB)\n","\u001b[K     |████████████████████████████████| 29.6 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from cpi) (2.8.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from cpi) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cpi) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cpi) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->cpi) (2022.2.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->cpi) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->cpi) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cpi) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cpi) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cpi) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cpi) (2.10)\n","Installing collected packages: cpi\n","Successfully installed cpi-1.0.11\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting adjustText\n","  Downloading adjustText-0.7.3.tar.gz (7.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from adjustText) (1.21.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from adjustText) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->adjustText) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->adjustText) (1.15.0)\n","Building wheels for collected packages: adjustText\n","  Building wheel for adjustText (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adjustText: filename=adjustText-0.7.3-py3-none-any.whl size=7097 sha256=acf56f6241d2ce52edf6b5ae01d98e5b90e99e51ef178ac763495f902b02020f\n","  Stored in directory: /root/.cache/pip/wheels/2f/98/32/afbf902d8f040fadfdf0a44357e4ab750afe165d873bf5893d\n","Successfully built adjustText\n","Installing collected packages: adjustText\n","Successfully installed adjustText-0.7.3\n"]}]},{"cell_type":"markdown","source":["# Approval rates"],"metadata":{"id":"tWg325ohk5RV"}},{"cell_type":"markdown","source":["# Get hold of the data and clean it"],"metadata":{"id":"d2Nc76gCk5wl"}},{"cell_type":"markdown","source":["### Data from Goldsten (2019) obtained through the Freedom for Information Act"],"metadata":{"id":"xP-9LBdulFfI"}},{"cell_type":"code","source":["SBA_dir = data_dir + 'SBA/'\n","\n","# Approved loans\n","df_approvals = pd.read_csv(SBA_dir + \"data/sba_disaster_loan_approvals.csv.gz\")\n","\n","# Withdrawn loans\n","df_withdrawals = pd.read_csv(SBA_dir + \"data/sba_disaster_loan_withdrawals.csv.gz\")\n","\n","# Declined loans\n","df_declines = pd.read_csv(SBA_dir + \"data/sba_disaster_loan_declines.csv.gz\")\n","\n","# Remove whitespace from decline code fields\n","df_declines[['DECL_CODES','DECL_CODES2','DECL_CODES3','DECL_CODES4','FEMA_DECL']] = df_declines[['DECL_CODES','DECL_CODES2','DECL_CODES3','DECL_CODES4','FEMA_DECL']].apply(lambda s: s.str.strip())\n","\n","# Remove whitespace from ends of state codes\n","df_approvals[['STATE']] = df_approvals[['STATE']].apply(lambda s: s.str.strip())\n","df_withdrawals[['STATE']] = df_withdrawals[['STATE']].apply(lambda s: s.str.strip())\n","df_declines[['STATE']] = df_declines[['STATE']].apply(lambda s: s.str.strip())\n","\n","# Looking only at HOME LOANS & LOANS BELOW 200K with FEMA verified losses\n","cols = ['ORIGINAL_APPROVAL_AMOUNT']\n","mask = df_approvals[cols].applymap(lambda x: isinstance(x, (int, float)))\n","df_approvals[cols] = df_approvals[cols].where(mask)\n","df_approvals = df_approvals[df_approvals['ORIGINAL_APPROVAL_AMOUNT'].astype(float)<210000].reset_index(drop=True)\n","df_approvals['FEMA_DECL'] = pd.to_numeric(df_approvals['FEMA_DECL'].str.replace('DR',''),errors='coerce')\n","\n","cols = ['TOT_ORIG_VER_LOSS']\n","mask = df_declines[cols].applymap(lambda x: isinstance(x, (int, float)))\n","df_declines[cols] = df_declines[cols].where(mask)\n","df_declines = df_declines[(df_declines['TOT_ORIG_VER_LOSS_RE'] > 100) & (df_declines['TOT_ORIG_VER_LOSS_RE'].astype(float)<210000)]\n","\n","# Remove data we would not have by 2017\n","df_approvals = df_approvals[df_approvals['FY'] < 2018].reset_index(drop=True)\n","\n","#df_approvals['InflationRates'] = df_approvals['FY'].astype(int).apply(lambda x: cpi.inflate(1,x,to=2021)) #map(inflation_dict)\n","df_approvals['ORIGINAL_APPROVAL_AMOUNT_2022_DOLLARS'] = df_approvals['ORIGINAL_APPROVAL_AMOUNT'] #* df_approvals['InflationRates']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_424L8fqk0yi","executionInfo":{"status":"ok","timestamp":1663353906236,"user_tz":240,"elapsed":16528,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"63917c67-8205-41b4-a465-5418ede76fdf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1,2,3,7,10) have mixed types.Specify dtype option on import or set low_memory=False.\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1,2,3,7,10,13,14,15) have mixed types.Specify dtype option on import or set low_memory=False.\n","/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (1,2,3,7,10,13,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n"]}]},{"cell_type":"markdown","source":["### Data from the OpenSBA portal"],"metadata":{"id":"8Epoy-x1lBso"}},{"cell_type":"code","source":["# Read\n","SBA_dir = data_dir + 'SBA/'\n","df_SBA_2008 = pd.read_csv(SBA_dir + \"SBA_FY08.txt\")\n","df_SBA_2009 = pd.read_csv(SBA_dir + \"SBA_FY09.txt\")\n","df_SBA_2010 = pd.read_csv(SBA_dir + \"SBA_FY10.txt\")\n","df_SBA_2011 = pd.read_csv(SBA_dir + \"SBA_FY11.txt\")\n","df_SBA_2012 = pd.read_csv(SBA_dir + \"SBA_FY12.txt\")\n","df_SBA_2013 = pd.read_csv(SBA_dir + \"SBA_FY13.txt\")\n","df_SBA_2014 = pd.read_csv(SBA_dir + \"SBA_FY14.txt\")\n","df_SBA_2015 = pd.read_csv(SBA_dir + \"SBA_FY15.txt\")\n","df_SBA_2016 = pd.read_csv(SBA_dir + \"SBA_FY16.txt\")\n","df_SBA_2017 = pd.read_csv(SBA_dir + \"SBA_FY17.txt\")\n","df_SBA_2018 = pd.read_csv(SBA_dir + \"SBA_FY18.txt\") # Not available in 2017\n","df_SBA_2019 = pd.read_csv(SBA_dir + \"SBA_FY19.txt\") # Not available in 2017\n","\n","df_SBA_All = pd.DataFrame()\n","df_SBA_All = df_SBA_All.append(df_SBA_2008[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2009[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2010[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2011[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2012[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2013[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2014[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2015[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2016[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.append(df_SBA_2017[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","#df_SBA_All = df_SBA_All.append(df_SBA_2018[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","#df_SBA_All = df_SBA_All.append(df_SBA_2019[['FEMA Disaster Number','Damaged Property State Code','Verified Loss Real Estate','Approved Amount Real Estate']])\n","df_SBA_All = df_SBA_All.dropna().reset_index(drop=True)\n","\n","df_SBA_All = df_SBA_All.rename(columns={\"Damaged Property State Code\": \"State\"})\n","\n","\n","# Get only the entries with an associated valid FEMA declaration number\n","cols = ['FEMA Disaster Number']\n","mask = df_SBA_All[cols].applymap(lambda x: isinstance(x, (int, float)))\n","df_SBA_All[cols] = df_SBA_All[cols].where(mask)\n","df_SBA_All['FEMA Disaster Number'] = df_SBA_All['FEMA Disaster Number'].astype(int).reset_index(drop=True)\n","\n","# Get the ratio of loan-to-loss\n","df_SBA_All['Ratio'] = df_SBA_All['Approved Amount Real Estate']/df_SBA_All['Verified Loss Real Estate']\n","\n","# Get only approved \n","df_SBA_All = df_SBA_All[df_SBA_All['Approved Amount Real Estate'] > 0].reset_index(drop=True)\n","\n","# If the loan approved is higher than the verified loss there is something wrong with this entry so I am removing it\n","# Using 1.05 to allow small adjustment to the loan amount \n","df_SBA_All = df_SBA_All[df_SBA_All['Ratio'] <= 1.05].reset_index(drop=True)\n","print('There are',len(df_SBA_All.index),'entries in total.')\n","\n","df_FEMA_Declarations = pd.read_csv(data_dir + \"DisasterDeclarationsSummaries.csv\")\n","df_FEMA_Declarations = df_FEMA_Declarations[df_FEMA_Declarations['fyDeclared']>2000]\n","df_FEMA_Declarations = df_FEMA_Declarations[df_FEMA_Declarations['declarationType'] == 'DR']\n","\n","codes = df_FEMA_Declarations['disasterNumber']\n","years = df_FEMA_Declarations['fyDeclared']\n","FEMADeclaration_dict = dict(zip(codes, years))\n","\n","hazard = df_FEMA_Declarations['incidentType']\n","FEMADeclarationHazard_dict = dict(zip(codes, hazard))\n","\n","# Disaster year\n","df_SBA_All['Year'] = df_SBA_All['FEMA Disaster Number'].map(FEMADeclaration_dict)\n","df_SBA_All = df_SBA_All[df_SBA_All['Year'].isna() == False].reset_index(drop=True)\n","\n","# Disaster hazard\n","df_SBA_All['Hazard'] = df_SBA_All['FEMA Disaster Number'].map(FEMADeclarationHazard_dict)\n","df_SBA_All['Hazard'] = df_SBA_All['Hazard'].replace(np.nan,'Unknown')\n","\n","# Inflation rate since year\n","df_SBA_All['InflationRate'] = df_SBA_All['Year'].astype(int).apply(lambda x: cpi.inflate(1,x,to=2021))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfFj8z4_lAw7","executionInfo":{"status":"ok","timestamp":1663353910386,"user_tz":240,"elapsed":4153,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"cdc2e159-9ca1-495b-a7a3-08cb1750072d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 15320 entries in total.\n"]}]},{"cell_type":"markdown","source":["## Get approval rate for selected state"],"metadata":{"id":"7gyqmzyclSST"}},{"cell_type":"code","source":["def getApprovalRateForSelectedState(state):\n","\n","    # All disasters between 2007 and 2019\n","    if state == 'All':\n","        df_Approvals_state = df_SBA_All.copy()\n","    else:  \n","        df_Approvals_state = df_SBA_All[df_SBA_All['State'] == 'CA'].copy()\n","\n","    return len(df_Approvals_state[df_Approvals_state['Approved Amount Real Estate'] > 0].index) / len(df_Approvals_state.index)"],"metadata":{"id":"Ul1vVnQilRrm","executionInfo":{"status":"ok","timestamp":1663353910386,"user_tz":240,"elapsed":6,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## <font color='blue'> Use the cell below to calculate the approval rate per state</font>"],"metadata":{"id":"P67Rrzu0l6RN"}},{"cell_type":"code","source":["getApprovalRateForSelectedState('CA')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xf5B2JbUl4d9","executionInfo":{"status":"ok","timestamp":1663353910387,"user_tz":240,"elapsed":6,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"2777ca36-abce-4fba-ad45-47d0d50be4c3"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Approved amount"],"metadata":{"id":"wIaGlOEvlZWj"}},{"cell_type":"markdown","source":["#### These cells manipulate the data, split aggregate data, and create a table of approval rates"],"metadata":{"id":"JFEkBFBVlhUQ"}},{"cell_type":"code","source":["def getSplitLosses(theState,theHazard,df_AllLoans,df_FOIAApprovals):\n","\n","    # Split loans between individual and aggregated\n","    if theState == 'All':\n","      df_ApprovedLoans = df_FOIAApprovals.copy()\n","      df_Ind = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] <= 210000) &\\\n","                          (df_AllLoans['Hazard']==theHazard)].copy().reset_index(drop=True)\n","\n","      df_Agg = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] > 210000) &\\\n","                          (df_AllLoans['Hazard']==theHazard)].copy().reset_index(drop=True)\n","\n","    elif theHazard == 'All':\n","      df_ApprovedLoans = df_FOIAApprovals[df_FOIAApprovals['STATE'] == theState].copy()\n","      df_Ind = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] <= 210000) &\\\n","                          (df_AllLoans['State']==theState)].copy().reset_index(drop=True)\n","\n","      df_Agg = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] > 210000) &\\\n","                          (df_AllLoans['State']==theState)].copy().reset_index(drop=True)\n","    \n","    else: \n","      df_ApprovedLoans = df_FOIAApprovals[df_FOIAApprovals['STATE'] == theState].copy()\n","      df_Ind = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] <= 210000) &\\\n","                          (df_AllLoans['State']==theState) &\\\n","                          (df_AllLoans['Hazard']==theHazard)].copy().reset_index(drop=True)\n","\n","      df_Agg = df_AllLoans[(df_AllLoans['Approved Amount Real Estate'] > 210000) &\\\n","                          (df_AllLoans['State']==theState) &\\\n","                          (df_AllLoans['Hazard']==theHazard)].copy().reset_index(drop=True)\n","\n","\n","    # Fit an exponential RV to the approved loans in the FOIA data\n","    \n","    X = np.array(df_ApprovedLoans['ORIGINAL_APPROVAL_AMOUNT'], dtype=float)#df_ApprovedLoans['ORIGINAL_APPROVAL_AMOUNT']\n","    cut,mu = sts.expon.fit(X)\n","\n","\n","    # Return df\n","    df_return = pd.DataFrame()\n","    v_ratio = list(df_Ind['Ratio'])\n","    v_amt = list(df_Ind['Approved Amount Real Estate'])\n","    v_loss = list(df_Ind['Verified Loss Real Estate'])\n","    v_ddnumber = list(df_Ind['FEMA Disaster Number'])\n","    v_state = list(df_Ind['State'])\n","    v_year = list(df_Ind['Year'])\n","    v_hazard = list(df_Ind['Hazard'])\n","\n","\n","    # Loop over each aggregated entry\n","    for i in range(len(df_Agg.index)):\n","\n","        # Get the value in this aggregated group\n","        totalLoan = df_Agg.loc[i,'Approved Amount Real Estate']\n","\n","        while totalLoan > 0:\n","\n","            # Estimate approved amount - note, the SBA cap is 200,000\n","            myApprovedAmount = min(np.random.exponential(mu,1)[0],200000)\n","\n","            # Fit a multinomial RV to the Loan-to-Loss ratio for the individual loan data\n","            theBins = list(range(0,11,1))\n","            theBins = [x / 10 for x in theBins]\n","\n","            # Get hold of the approved amount near the randomly assigned to this building\n","            df_Near = df_Ind[(df_Ind['Approved Amount Real Estate'] > myApprovedAmount - 50000)\\\n","                                                    & (df_Ind['Approved Amount Real Estate'] < myApprovedAmount + 50000)].copy()\n","\n","            count, division = np.histogram(df_Near[df_Near['Ratio']>0]['Ratio'],bins=theBins)\n","            p = count/np.sum(count)\n","            s = list(range(0,10,1))\n","            s = [x / 10 for x in s]\n","\n","            # Estimate ratio within the 0.1-brackets\n","            myRatio = rng.choice(s,p=p,size=1)[0] + rng.random(1)[0]/10\n","            \n","            # Main calculations\n","            v_ratio.append(myRatio)\n","            v_amt.append(myApprovedAmount)\n","            v_loss.append(myApprovedAmount/myRatio)\n","\n","            # Others\n","            v_ddnumber.append(df_Agg.loc[i,'FEMA Disaster Number'])\n","            v_state.append(df_Agg.loc[i,'State'])\n","            v_year.append(df_Agg.loc[i,'Year'])\n","            v_hazard.append(df_Agg.loc[i,'Hazard'])\n","\n","            totalLoan -= myApprovedAmount\n","\n","    df_return['FEMA Disaster Number'] = v_ddnumber\n","    df_return['State'] = v_state\n","    df_return['Verified Loss Real Estate'] = v_loss\n","    df_return['Approved Amount Real Estate'] = v_amt\n","    df_return['Ratio'] = v_ratio\n","    df_return['Year'] = v_year\n","    df_return['Hazard'] = v_hazard\n","\n","    return df_return\n","\n","\n","def getApprovedAmountMatrixForSelectedState(state,hazard):\n","\n","    df_sba = getSplitLosses(state,hazard,df_SBA_All,df_approvals)\n","\n","    # Check in which bracket the losses for each applicant are\n","    out = pd.DataFrame()\n","\n","    # Gather data for the selected state\n","    lossbins = list(range(0,500001,50000))\n","    lossbins.append(1000000)\n","\n","    #print('The results are based on',len(df_State.index),'data points.')\n","\n","    for i in range(len(lossbins)-1):\n","        df = df_sba[df_sba['Verified Loss Real Estate'].apply(lambda x: True if lossbins[i] <= x < lossbins[i+1] else False)]\n","        theBins = list(range(0,11,1))\n","        theBins = [x / 10 for x in theBins]\n","        count, division = np.histogram(df['Ratio'],bins=theBins)\n","        \n","        out[str(lossbins[i+1])] = count/np.sum(count)\n","\n","    out.to_csv(data_dir+'SBA/ApprovalAmountMatrix_' + str(state) + '_' + str(hazard) +'.txt', index=False)\n","    return out"],"metadata":{"id":"7kPtbJ0UlYiO","executionInfo":{"status":"ok","timestamp":1663353980560,"user_tz":240,"elapsed":158,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## <font color='blue'> Use the cell below to calculate the approval amounts per state and hazard </font>"],"metadata":{"id":"me52XIr1m17-"}},{"cell_type":"code","source":["# Enter 'All' if you do not want to filter by state or hazard\n","#                                        state,hazard\n","getApprovedAmountMatrixForSelectedState('All','Flood')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"AgIQ_RTolfiu","executionInfo":{"status":"ok","timestamp":1663353997485,"user_tz":240,"elapsed":12643,"user":{"displayName":"Rodrigo Costa","userId":"15201424764589684325"}},"outputId":"1593cb49-1b2b-4ccc-be22-0ab644da7a80"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      50000    100000    150000    200000    250000    300000    350000  \\\n","0  0.011299  0.022727  0.030169  0.072404  0.064665  0.101351  0.175532   \n","1  0.038230  0.070804  0.097604  0.124317  0.159353  0.179054  0.180851   \n","2  0.075895  0.124126  0.167702  0.176230  0.217090  0.219595  0.202128   \n","3  0.069115  0.113636  0.141970  0.154372  0.150115  0.195946  0.191489   \n","4  0.075895  0.106206  0.138421  0.166667  0.145497  0.114865  0.127660   \n","5  0.080791  0.096154  0.125111  0.103825  0.131640  0.121622  0.090426   \n","6  0.106026  0.117570  0.133984  0.109290  0.069284  0.057432  0.031915   \n","7  0.144444  0.120629  0.080745  0.051913  0.023095  0.010135  0.000000   \n","8  0.148211  0.096154  0.036380  0.024590  0.023095  0.000000  0.000000   \n","9  0.250094  0.131993  0.047915  0.016393  0.016166  0.000000  0.000000   \n","\n","     400000    450000    500000   1000000  \n","0  0.227273  0.211009  0.333333  0.407018  \n","1  0.246753  0.266055  0.222222  0.280702  \n","2  0.253247  0.266055  0.277778  0.245614  \n","3  0.084416  0.100917  0.097222  0.066667  \n","4  0.097403  0.155963  0.069444  0.000000  \n","5  0.090909  0.000000  0.000000  0.000000  \n","6  0.000000  0.000000  0.000000  0.000000  \n","7  0.000000  0.000000  0.000000  0.000000  \n","8  0.000000  0.000000  0.000000  0.000000  \n","9  0.000000  0.000000  0.000000  0.000000  "],"text/html":["\n","  <div id=\"df-f5197d82-83d0-46d2-bc82-079028ce74b8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>50000</th>\n","      <th>100000</th>\n","      <th>150000</th>\n","      <th>200000</th>\n","      <th>250000</th>\n","      <th>300000</th>\n","      <th>350000</th>\n","      <th>400000</th>\n","      <th>450000</th>\n","      <th>500000</th>\n","      <th>1000000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.011299</td>\n","      <td>0.022727</td>\n","      <td>0.030169</td>\n","      <td>0.072404</td>\n","      <td>0.064665</td>\n","      <td>0.101351</td>\n","      <td>0.175532</td>\n","      <td>0.227273</td>\n","      <td>0.211009</td>\n","      <td>0.333333</td>\n","      <td>0.407018</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.038230</td>\n","      <td>0.070804</td>\n","      <td>0.097604</td>\n","      <td>0.124317</td>\n","      <td>0.159353</td>\n","      <td>0.179054</td>\n","      <td>0.180851</td>\n","      <td>0.246753</td>\n","      <td>0.266055</td>\n","      <td>0.222222</td>\n","      <td>0.280702</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.075895</td>\n","      <td>0.124126</td>\n","      <td>0.167702</td>\n","      <td>0.176230</td>\n","      <td>0.217090</td>\n","      <td>0.219595</td>\n","      <td>0.202128</td>\n","      <td>0.253247</td>\n","      <td>0.266055</td>\n","      <td>0.277778</td>\n","      <td>0.245614</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.069115</td>\n","      <td>0.113636</td>\n","      <td>0.141970</td>\n","      <td>0.154372</td>\n","      <td>0.150115</td>\n","      <td>0.195946</td>\n","      <td>0.191489</td>\n","      <td>0.084416</td>\n","      <td>0.100917</td>\n","      <td>0.097222</td>\n","      <td>0.066667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.075895</td>\n","      <td>0.106206</td>\n","      <td>0.138421</td>\n","      <td>0.166667</td>\n","      <td>0.145497</td>\n","      <td>0.114865</td>\n","      <td>0.127660</td>\n","      <td>0.097403</td>\n","      <td>0.155963</td>\n","      <td>0.069444</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.080791</td>\n","      <td>0.096154</td>\n","      <td>0.125111</td>\n","      <td>0.103825</td>\n","      <td>0.131640</td>\n","      <td>0.121622</td>\n","      <td>0.090426</td>\n","      <td>0.090909</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.106026</td>\n","      <td>0.117570</td>\n","      <td>0.133984</td>\n","      <td>0.109290</td>\n","      <td>0.069284</td>\n","      <td>0.057432</td>\n","      <td>0.031915</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.144444</td>\n","      <td>0.120629</td>\n","      <td>0.080745</td>\n","      <td>0.051913</td>\n","      <td>0.023095</td>\n","      <td>0.010135</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.148211</td>\n","      <td>0.096154</td>\n","      <td>0.036380</td>\n","      <td>0.024590</td>\n","      <td>0.023095</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.250094</td>\n","      <td>0.131993</td>\n","      <td>0.047915</td>\n","      <td>0.016393</td>\n","      <td>0.016166</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5197d82-83d0-46d2-bc82-079028ce74b8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f5197d82-83d0-46d2-bc82-079028ce74b8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f5197d82-83d0-46d2-bc82-079028ce74b8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]}]}